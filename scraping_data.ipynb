{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Teste com apenas Shooting em um ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "data = requests.get(standings_url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data.text)\n",
    "print(soup)\n",
    "standings_table = soup.select(\"table.stats_table\")[0]\n",
    "print(standings_table)\n",
    "links = standings_table.find_all('a')\n",
    "links = [l.get(\"href\") for l in links]\n",
    "links = [l for l in links if '/squads/' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_url = [f\"https://fbref.com{l}\" for l in links]\n",
    "team_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_url = team_url[0]\n",
    "data = requests.get(team_url)\n",
    "matches = pd.read_html(data.text, match=\"Scores & Fixtures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data.text)\n",
    "links = soup.find_all('a')\n",
    "links = [l.get(\"href\") for l in links]\n",
    "links = [l for l in links if l and \"all_comps/shooting/\" in l]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "shooting = pd.read_html(data.text, match=\"Shooting\")[0]\n",
    "shooting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shooting.columns = shooting.columns.droplevel()\n",
    "shooting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = matches[0].merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on= \"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Iterando em anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2022,2020,-1))\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = []\n",
    "standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    data = requests.get(standings_url)\n",
    "    soup = BeautifulSoup(data.text)\n",
    "    standings_table = soup.select('table.stats_table')[0]\n",
    "\n",
    "    links = [l.get(\"href\") for l in standings_table.find_all('a')]\n",
    "    links = [l for l in links if \"/squads/\" in l]\n",
    "    team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
    "\n",
    "    previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
    "    standings_url = f\"https://fbref.com{previous_season}\"\n",
    "\n",
    "    for team_url in team_urls:\n",
    "        team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
    "        \n",
    "        data = requests.get(team_url)\n",
    "        print(team_url)\n",
    "        matches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]\n",
    "        \n",
    "\n",
    "        soup = BeautifulSoup(data.text)\n",
    "        links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "        links = [l for l in links if l and \"all_comps/shooting/\" in l]\n",
    "        data = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "        shooting = pd.read_html(data.text, match=\"Shooting\")[0]\n",
    "        #print(shooting)\n",
    "        shooting.columns = shooting.columns.droplevel()\n",
    "\n",
    "        try:\n",
    "            team_data = matches.merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on= \"Date\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n",
    "        team_data[\"Season\"] = year\n",
    "        team_data[\"Team\"] = team_name\n",
    "        all_matches.append(team_data)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.concat(all_matches)\n",
    "match_df.columns = [c.lower() for c in match_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.to_csv(\"matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code using functions, iterating from 2023 to 2018 and for all teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_urls(standings_url):\n",
    "    data = requests.get(standings_url)\n",
    "    soup = BeautifulSoup(data.text)\n",
    "    standings_table = soup.select('table.stats_table')[0]\n",
    "\n",
    "    links = [l.get(\"href\") for l in standings_table.find_all('a')]\n",
    "    links = [l for l in links if \"/squads/\" in l]\n",
    "    team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
    "    return team_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_season_url(current_season_url):\n",
    "    data = requests.get(current_season_url)\n",
    "    soup = BeautifulSoup(data.text, 'html.parser')\n",
    "    previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
    "    return f\"https://fbref.com{previous_season}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_process_team_data(team_url, year, end_link):\n",
    "    try:\n",
    "        team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
    "        data = requests.get(team_url)\n",
    "        #print(team_url)\n",
    "        matches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]\n",
    "\n",
    "        soup = BeautifulSoup(data.text)\n",
    "        links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "        links = [l for l in links if l and end_link in l]\n",
    "\n",
    "        team_data = pd.DataFrame()\n",
    "\n",
    "        if links:\n",
    "            data = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "            \n",
    "            if end_link == \"all_comps/shooting/\":\n",
    "                shooting = pd.read_html(data.text, match=\"Shooting\")[0]\n",
    "                shooting.columns = shooting.columns.droplevel()\n",
    "                print(\"shooting\")\n",
    "                try:\n",
    "                    team_data = matches.merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")            \n",
    "                except ValueError:\n",
    "                    pass\n",
    "            if end_link == \"all_comps/keeper/\":\n",
    "                goalkeeper = pd.read_html(data.text, match=\"Goalkeeping\")[0]\n",
    "                goalkeeper.columns = goalkeeper.columns.droplevel()\n",
    "                print(\"keeper\")\n",
    "                try:\n",
    "                    team_data = matches.merge(goalkeeper[[\"Date\", \"Saves\", \"Save%\", \"CS\", \"PKatt\", \"PKA\", \"PKsv\", \"PKm\"]], on=\"Date\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            if end_link == \"all_comps/passing/\":\n",
    "                passing = pd.read_html(data.text, match=\"Passing\")[0]\n",
    "                passing.columns = passing.columns.droplevel()\n",
    "                print(\"passing\")\n",
    "                try:\n",
    "                    team_data = matches.merge(passing[[\"Date\", \"Cmp\", \"Att\", \"Cmp%\", \"TotDist\", \"PrgDist\"]], on=\"Date\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            if end_link == \"all_comps/possession/\":\n",
    "                possession = pd.read_html(data.text, match=\"Possession\")[0]\n",
    "                possession.columns = possession.columns.droplevel()\n",
    "                print(\"possession\")\n",
    "                try:\n",
    "                    team_data = matches.merge(possession[[\"Date\", \"Touches\", \"Def Pen\", \"Def 3rd\", \"Mid 3rd\", \"Att 3rd\", \"Att Pen\", \"Live\"]], on=\"Date\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            print(\"No matching links found.\")\n",
    "\n",
    "        team_data[\"Season\"] = year\n",
    "        team_data[\"Team\"] = team_name\n",
    "        time.sleep(5)\n",
    "        return team_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {team_url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(years, initial_standings_url):\n",
    "    all_matches = []\n",
    "    links_list = [\"all_comps/shooting/\", \"all_comps/keeper/\", \"all_comps/passing/\", \"all_comps/possession/\"]\n",
    "\n",
    "    standings_url = initial_standings_url\n",
    "    while standings_url:\n",
    "        print(f\"Processing standings URL: {standings_url}\")\n",
    "        if standings_url.find(years) != -1:\n",
    "            break\n",
    "        else:\n",
    "            team_urls = get_team_urls(standings_url)\n",
    "\n",
    "            if not team_urls:\n",
    "                print(\"No team URLs found.\")\n",
    "                break\n",
    "\n",
    "            for team_url in team_urls:\n",
    "                team_data_list = []  # Create a list to store data for each type of statistic\n",
    "                for end_link in links_list:\n",
    "                    team_data = fetch_and_process_team_data(team_url, years.replace(\"/\", \"\"), end_link)\n",
    "\n",
    "                    if team_data is not None:\n",
    "                        # Reset the column names for each type of statistic DataFrame\n",
    "                        team_data.columns = [f\"{end_link[:-1]}_{c}\" if c != 'Date' else c for c in team_data.columns]\n",
    "                        team_data_list.append(team_data)\n",
    "\n",
    "                if team_data_list:\n",
    "                    # Concatenate data for different types of statistics for the same team\n",
    "                    team_data_combined = pd.concat(team_data_list, axis=1)\n",
    "                    all_matches.append(team_data_combined)\n",
    "\n",
    "            standings_url = get_previous_season_url(standings_url)\n",
    "\n",
    "    return pd.concat(all_matches, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing standings URL: https://fbref.com/en/comps/9/Premier-League-Stats\n",
      "shooting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m years \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/2017-2018/2017-2018\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m initial_standings_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://fbref.com/en/comps/9/Premier-League-Stats\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Initial URL\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m result \u001b[39m=\u001b[39m main(years, initial_standings_url)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(result)\n\u001b[0;32m      7\u001b[0m result\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [c\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mcolumns]\n",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(years, initial_standings_url)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m team_url \u001b[39min\u001b[39;00m team_urls:\n\u001b[0;32m     20\u001b[0m     \u001b[39mfor\u001b[39;00m end_link \u001b[39min\u001b[39;00m links_list:\n\u001b[1;32m---> 21\u001b[0m         team_data \u001b[39m=\u001b[39m fetch_and_process_team_data(team_url, years\u001b[39m.\u001b[39;49mreplace(\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m), end_link)\n\u001b[0;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m team_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m         all_matches\u001b[39m.\u001b[39mappend(team_data)\n",
      "Cell \u001b[1;32mIn[5], line 58\u001b[0m, in \u001b[0;36mfetch_and_process_team_data\u001b[1;34m(team_url, year, end_link)\u001b[0m\n\u001b[0;32m     56\u001b[0m     team_data[\u001b[39m\"\u001b[39m\u001b[39mSeason\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m year\n\u001b[0;32m     57\u001b[0m     team_data[\u001b[39m\"\u001b[39m\u001b[39mTeam\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m team_name\n\u001b[1;32m---> 58\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m team_data\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    years = \"/2017-2018/2017-2018\"\n",
    "    initial_standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"  # Initial URL\n",
    "\n",
    "    result = main(years, initial_standings_url)\n",
    "    print(result)\n",
    "    result.columns = [c.lower() for c in result.columns]\n",
    "    result.to_csv(\"matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
